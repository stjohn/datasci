<!DOCTYPE doctype PUBLIC "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
  <meta http-equiv="Content-Type"
 content="text/html; charset=iso-8859-1">
  <title>CSci 39542: Data Science, Hunter College</title>
</head>
<STYLE>A {text-decoration: none;}
th, td { padding: 5px; border: 1px solid black}
table { border: 1px solid black; border-collapse: collapse}</STYLE>
<body>


<div style="margin: 15px;">
    <span style= "float: left;font-size:larger"><a href="index.html">CSci 39542</a></span>
    <span style= "float: right">
      <a href="syl.html">Syllabus</a>&nbsp;&nbsp;&nbsp;
      <a href="resources.html">Resources</a>&nbsp;&nbsp;&nbsp;
      <a href="work.html">Coursework</a>&nbsp;&nbsp;&nbsp;
      <a href="faq.html">FAQ</a>
    </span>
</div>

<br>
<br>
<hr>

<div style="margin:50px">


<h2>CSci 39542: Introduction to Data Science<br>
<a href="http://www.hunter.cuny.edu/csci">Department of Computer Science</a><br>
<a href="https://hunter.cuny.edu">Hunter College</a>, <a href="https://www.cuny.edu">City University of New York</a><br>
Fall 2023<br><br>
</h2>

<i>TL;DR: data-focused programming course with optional project.</i>

<br><br>
<p>
For questions about the course, write to: <tt>datasci AT hunter cuny edu</tt>.<!--or visit <a href="https://stjohn.github.io/teaching/officeHours.html">office hours</a>.-->
</p>

<h3>Announcements:</h3>



<ul>
  <li> Enrollment is closed for this semester.</li>
<!--  
  <li> The course will meet Wednesdays, 11:30am-2:15pm in HN C002.
  <li> The course prerequisites for this programming-intensive class are:
      <p>
      <ul>
          <li> a year of college-level programming in the same language ((CSci 127 & 133) or (CSci 135 & 235)),
          <li> at least one semester in Python (i.e. CSci 127), and
          <li> a course in statistics (i.e. Stat 213 or equivalent).
      </ul>
  <p> If you are interested in the course and have a year of programming, Python proficiency, and taken statistics, you can enroll directly via CUNYFirst without additional permissions.  If you took the courses elsewhere, reach out to a computer science advisor about what's needed to align your previous courses to Hunter courses on your CUNYFirst record.
  <li> Enrollment for the course is via CUNYFirst.  Fall enrollment opens in early May.

  <li> The course is full, and we do not expect additional seats to become available for the fall term.  We anticipate that the course will be offered again in the spring.
  Enrollment for the course is via CUNYFirst.  If the course is at capacity, sign up for the wait list.  Those on the wait list have first priority when seats become available.</li>
  <li> Enrolled Students:  for the quickest response to questions, use the links on the course Blackboard page:
      <ul>
          <li> For questions of general interest, use <code class="inline">Help::General Questions</code>.
          <li> For questions specific to you (e.g. resending Gradescope invitations, questions about grading, etc.), use <code class="inline">Help::Individual Questions</code>.
      </ul>
  -->
</ul>


<br>
<h3>Calendar:</h3>

<i>Tentative schedule, subject to change:</i>

<table >
	<tr>
    <th style="text-align: left">Week:</th>
		<th style="text-align: left"></th>
		<th style="text-align: left"><b>Topics:</b></th>
		<th style="text-align: left"><b>Coursework:</b></th>
		<th style="text-align: left"><b>Reading:</b></th>

	</tr>
	<tr>
    <td>Week 0:</td>
		<td>Friday,<br> 25 August</td>
		<td><a href="syl.html">Syllabus</a> & <a href="faq.html">Frequently Asked Questions</a>
		</td>

		<td> 
      <a href="work.html#cw0">Classwork 0</a>
    </td>
    <td></td>
  </tr>

	<tr>
    <td>Week 1:</td>
		<td>Wednesday, <br>30 August</td>
		<td><a href="syl.html">Syllabus</a> & Class Policies;<br><br>
      <!--Overview & Gallery;<br>-->
      Data Science Lifecycle:  Question Formulation,
        Data Acquisition and Cleaning,
        Exploratory Data Analysis,
        Prediction and Inference,<br><br>
        Data Scope, Big Data, Accuracy<br><br>

      Python Recap: dictionaries, I/O, keyword parameters, & linting

		</td>

		<td> 
      <a href="work.html#cw1_1">Classwork 1</a>
    </td>

		<td><a href="http://learningds.org/ch/01/lifecycle_intro.html">DS 100: Chapter 1</a> (Data Science Lifecycle),<br>
      <a href="http://learningds.org/ch/02/data_scope_intro.html">DS 100: Chapter 2</a> (Data Scope),<br>
      <a href="http://learningds.org/ch/04/modeling_intro.html">DS 100: Chapter 4</a> (Modeling with Summary Statistics),<br>    
      <br>
      <a href="https://runestone.academy/ns/books/published//thinkcspy/Dictionaries/toctree.html">Think CS: Chapter 12</a> (Dictionaries),<br>
      <a href="http://learningds.org/ch/13/text_strings.html">DS 100: Section 13.1</a> (String Methods),<br>
      <a href="https://runestone.academy/ns/books/published//thinkcspy/Files/toctree.html">Think CS: Chapter 11</a> (Files),<br>
       <a href="https://docs.python.org/3/tutorial/controlflow.html#more-on-defining-functions?">python.org: Section 4.7</a> (Functions),<br>
      <a href="https://pylint.readthedocs.io/en/latest/">pylint documentation</a>
    
    </td>
  </tr>
 
	<tr>
    <td rowspan="2">Week 2:</td>    
		<td>Wednesday,<br> 6 September</td>
		<td>
      Statistics Recap:  Expectation, Variance, Correlation, Residuals & Sampling<br><br>
      Linear Regression, Loss Functions:  Mean Squared and Mean Absolute Error,
      Data Representation, DataFrames (Pandas)<br><br>
      Python Recap: Lambda Expressions & Applying Functions
    </td>
    <td>
      <a href="work.html#cw2">Classwork 2</a><br>
    </td>
  	<td rowspan=1>
      <a href="https://seeing-theory.brown.edu/index.html">Seeing Theory</a> (Brown U),<br>
      <a href="https://www.geogebra.org/m/KE6JfuF9">Guessing Correlation Coefficients</a> (GeoGebra),<br>
      <a href="https://realpython.com/numpy-scipy-pandas-correlation-python/">Computing Correlations</a> (Real Python), <br>
      <a href="https://shiney.zoology.ubc.ca/whitlock/Residuals/">Residuals</a> (UBC),<br>
      <br>          
      <a href="http://learningds.org/ch/03/theory_intro.html">DS 100: Chapter 3</a> (Simulation & Data Design),<br>

      <a href="http://learningds.org/ch/15/linear_intro.html">DS 100: Chapter 15</a> (Linear Models),<br><br>

 
      <a href="http://learningds.org/ch/06/pandas_intro.html">DS 100: Chapter 6</a> (DataFrames),<br>
      <a href="https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html">Constructing DataFrames</a> (pydata.org) <br>     
      <a href="http://learningds.org/ch/08/files_granularity.html">DS 100: Section 8.5</a> (Table Shape & Granularity),<br>       

      <a href="https://docs.python.org/3/tutorial/controlflow.html#more-on-defining-functions?">python.org: Section 4.7</a> (Functions)
    
    </td>
  </tr>

  <tr>
    <td>Friday,<br> 8 September</td>
    <td></td>
    <td><a href="work.html#p1">Program 1</a><br></td>
    <td></td>
  </tr>

	<tr>
    <td>Week 3:</td>    
    <td rowspan=1>Wednesday,<br> 13 September</td>
		<td>
      Multiple Linear Regression, Handling Missing Values (Imputation), 
      Feature Engineering: Categorical Encoding  <br><br>

      Joining & Transforming Data in Pandas<br><br>

      Python Recap:  List comprehensions & zips      <br><br>
      
      <a href="work.html#project">Project Overview</a>
    </td>
    <td>
      <a href="work.html#cw3">Classwork 3</a>
    </td>
    <td>
      <a href="http://learningds.org/ch/06/pandas_intro.html">DS 100: Chapter 6</a> (DataFrames), <br>    
      <a href="http://learningds.org/ch/09/wrangling_intro.html">DS 100: Chapter 9</a> (Data Wrangling),<br>
      <a href="http://learningds.org/ch/15/linear_intro.html">DS 100: Chapter 15</a> (Linear Models),<br>     
      <br>
      <a href="https://runestone.academy/ns/books/published//thinkcspy/Lists/ListComprehensions.html">Think CS: Section 10.23</a> (List Comprehensions),<br>
      <a href="https://realpython.com/python-zip-function/">Zip Tutorial</a> (RealPython)
    
    </td>
	</tr>

	<tr>
    <td rowspan=2>Week 4:</td>    
		<td rowspan=1>Wednesday,<br> 20 September<br></span></td>
		<td>
      Fitting Models with sklearn, More on Loss Functions<br><br>

      Visualizing Qualitative & Quantitative Data, Time-Series Data,<br>
      Customizing Plots in plotly, matplotlib & seaborn<br><br>
   
      Serializing & Evaluating Models (pickling)<br>
      Python recap:  dates & times<br>

      Project Overview
      
    </td>
    <td>
      <a href="work.html#cw4">Classwork 4</a><br>
    </td>
		<td rowspan=1>
      <a href="http://learningds.org/ch/04/modeling_loss_functions.html">DS 100, Sections 4.2-3</a> (Loss Functions),<br>      
      <a href="http://learningds.org/ch/10/eda_intro.html">DS 100: Chapter 10</a> (Exploratory Data Analysis), <br>
      <a href="http://learningds.org/ch/11/viz_intro.html">DS 100: Sections 11.1-11.3</a> (Data Visualization),<br>
      <a href="http://learningds.org/ch/15/linear_intro.html">DS 100: Chapter 15</a> (Linear Models),<br>
      <br>      
      <a href="https://docs.python.org/3/library/pickle.html">Python Object Serialization Docs</a> (Pickling), <br>     
      <a href="https://github.com/ageron/handson-ml2/blob/master/tools_matplotlib.ipynb">Hands On ML</a> (Matplotlib Tools)
    </td>
	</tr>

  <tr>
    <td>Friday,<br> 22 September</td>
    <td></td>
    <td><a href="work.html#p2">Program 2</a></td>
    <td></td>
  </tr>  

	<tr>
    <td>Week 5:</td>
		<td rowspan="1">Wednesday,<br>27 September</td>
		<td>
      Visualizing GIS Data: GeoJSON Format, Choropleth Maps, Voronoi Diagrams, Visualization Principles<br><br>  

      Polynomial Models, 
      Training Models: Cross Validation, Ridge Regularization (L2) &
      Lasso Regularization (L1);    
      Bias-Variance Tradeoff<br>      
      More on Fitting Models:  Convexity, Validating, & Gradient Descent<br><br>
      Testing Frameworks
    </td>

		<td>      
      <a href="work.html#cw5">Classwork 5</a>
      
      
    </td>
		<td>   
      <a href="https://inferentialthinking.com/chapters/15/Prediction.html">DS 8: Chapter 15</a> (Prediction),<br>
      <a href="http://learningds.org/ch/11/viz_intro.html">DS 100: Chapter 11</a> (Data Visualization), <br>    
      <a href="http://learningds.org/ch/15/linear_multi.html">DS 100: Chapter 15.4</a> (Multiple Linear Regression),<br>  

      <a href="http://learningds.org/ch/15/linear_feature_eng.html">DS 100: Chapter 15.7</a> (Feature Engineering),<br>   
      <a href="https://learningds.org/ch/16/ms_cv.html">DS 100: Chapter 16.3</a> (Cross Validation),<br>
      <a href="https://learningds.org/ch/20/gd_basics.html">DS 100: Chapter 20</a> (Gradient Descent),<br><br>

      <a href="https://pypi.org/project/folium/">Folium documentation</a>,<br>
      <a href="http://geojson.io/">GeoJSON Editor</a> 
      <a href="https://github.com/lilipads/gradient_descent_viz">Gradient Descent Visualization</a>  (Lili Jiang),<br>
      <a href="https://runestone.academy/ns/books/published/thinkcspy/UnitTesting/toctree.html">ThinkCS:  Unit Testing</a>,
      <a href="https://docs.pytest.org/en/7.4.x/">Pytest</a>
    </td>
	</tr>

c	<tr>
    <td rowspan="2">Week 6:</td>
		<td rowspan="1">Wednesday, <br>4 October</td>

		<td>
      Probability and Generalization:  Distributions, Probability Mass Functions, Confidence Intervals, Smoothing;<br>
      Hypothesis Testing, Central Limit Theorem<br><br> 

      Review
    </td>
		<td>
      <a href="work.html#cw6">Classwork 6</a> <br>
      <br>
      <br>
      <a href="work.html#opt_in">Opt-in for Optional Project</a>
    </td>
    <td>   
      <a href="https://learningds.org/ch/17/inf_pred_gen_intro.html">DS 100: Chapter 17</a> (Theory for Inference & Prediction), <br>        
      <a href="https://learningds.org/ch/17/inf_pred_gen_intro.html">DS 100: Chapter 17</a> (Probability & Generalization), <br><br>

      <a href="https://www.zoology.ubc.ca/~whitlock/Kingfisher/SamplingNormal.htm"> Sampling from a Normally Distributed Population</a> (UBC),<br>

      <a href="https://www.zoology.ubc.ca/~whitlock/Kingfisher/CLT.htm">Central Limit Theorem</a> (UBC),<br>
      <a href="https://www.zoology.ubc.ca/~whitlock/Kingfisher/CIMean.htm">Confidence Intervals</a> (UBC)
    </td>
  </tr>

  <tr>
    <td>Friday,<br> 6 October</td>
    <td></td>
    <td>		
      <a href="work.html#p3">Program 3</a>
    </td>
    <td></td>
  </tr>

	<tr>
    <td rowspan="2">Week 7:</td>
		<td rowspan="1">Wednesday, <br>11 October</td>
		<td colspan="1">
      <a href="work.html#midterm">Midterm Exam</a><br>     
    </td>
    <td> 
      <a href="work.html#cw7">Classwork 7</a> 
    </td>	 
    <td> </td>
  </tr>

  <tr>
    <td> 
      <td>Thursday, <br> 12 October</td>
      <td><a href="work.html#preproposal">Project Proposal Window Opens</a></td>
    </td>	
    <td></td>
  </tr>

	<tr>
    <td rowspan="2">Week 8:</td>
		<td rowspan="1">Wednesday,<br>18 October</td>
    <td>
      <br>
      Regression on Probabilities; The Logistic Model & Loss Function;
      Using Logistic Models: Fitting & Evaluating a Logistic Model   <br><br> 
    
      Linear Algebra Recap:  Vectors, Matrices, Eigenvectors & Eigenvalues<br><br>
      Classification: Support Vector Machines (SVM's)
      <br><br> 
    </td>
    <td> 
      <a href="work.html#cw8">Classwork 8</a> 
    </td>	   
	
    <td>
    <a href="http://learningds.org/ch/19/classification_intro.html">DS 100: Chapter 19</a> (Classification),<br><br>
      
    <a href="https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py">Recognizing Hand-Written Digits</a> (sklearn)<br>   
    <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html">Confusion Matrices</a> (sklearn)<br><br>


    <a href="https://setosa.io/ev/eigenvectors-and-eigenvalues/">Explained Visually</a> (Eigenvectors and Eigenvalues),<br>
    <a href="https://math.mit.edu/~gs/linearalgebra/ila6/indexila6.html">Linear Algebra Review</a> (MIT),<br><br>

    <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html">Python DS Handbook Chapter 5</a> (SVMs),<br>

    <a href="https://cs.stanford.edu/~karpathy/svmjs/demo/">Karparthy's SVM Demo</a> (Stanford),<br>

    <a href="https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python">Data Camp Tutorial</a> (SVM's)<br>
    <a href="https://scikit-learn.org/stable/modules/svm.html">SVM's</a> (sklearn),<br>
    
    </td>
	</tr>

  <tr>
    <td>Friday,<br> 22 October</td>
    <td></td>
    <td> 
      <a href="work.html#proposal">Proposal for Optional Project</a>
    </td>
    <td></td>	    
  </tr>

	<tr>
    <td rowspan="1">Week 9:</td>
		<td rowspan="1">Wednesday,<br>25 October</td>
		<td>
      Multi-class Classification; 
      Other Classifiers:  Naive Bayes, Decision Trees & Random Forests<br><br>

      Intrinsic Dimensionality (Scree Plots);
      Principal Components Analysis (PCA)
    </td>
		<td>
      
      <a href="work.html#cw9">Classwork 9</a> 
    </td>    

		<td>    <a href="http://learningds.org/ch/19/classification_intro.html">DS 100: Chapter 19</a> (Classification),<br>
      <a href="http://learningds.org/ch/22/pca_intro.html">DS 100: Chapter 22</a> (PCA)<br><br>

    <a href="http://www.r2d3.us">Decisions Trees; Bias & Variance</a> (R2D3)  
      <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html">Python DS Handbook: Section 5.09</a> (PCA),<br>
      <a href="https://setosa.io/ev/principal-component-analysis/">Explained Visually</a> (Principal Components Analysis),<br>

      </td>
	</tr>

 


	<tr>
    <td rowspan="2">Week 10:</td>
		<td rowspan="1">Wednesday,<br>1 November</td>
		<td> 
      
      Multidimensional Scaling (MDS); Non-Euclidean Distances <br><br>

      Other Dimensionality Reduction:  Multiple Dimensional Scaling; 
      Non-Linear Dimensionality Reduction:  t-SNE, UMAP
    </td>
		<td>
      <a href="work.html#cw10">Classwork 10</a> 
    </td>    

    <td>      

      <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.10-manifold-learning.html">Python DS Handbook Section 5.10</a> (Manifold Learning),<br>
      <a href="https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#sphx-glr-auto-examples-manifold-plot-lle-digits-py">Manifold Learning</a> (sklearn), <br>
   
    </td>
	</tr>
  <tr>
    <td>Friday,<br> 3 November</td>
    <td></td>
    <td>	
      <a href="work.html#p4">Program 4</a>
    </td>
    <td></td>
  </tr> 


	<tr> 
    <td rowspan="2">Week 11:</td>
		<td rowspan="1">Wednesday,<br>8 November</td>
		<td>K-Means Clustering:  Clustering Complexity, Lloyd's Algorithm (Naive K-Means), MiniBatch;<br>
      More on Clustering: Gaussian Mixture Models; Hierarchical Clustering;
      <br><br>
    Regular Expressions<br>
  </td>
  <td>     
    <a href="work.html#cw11">Classwork 11</a>
  </td>    

    <td>
      <a href="https://en.wikipedia.org/wiki/K-means_clustering#/media/File:K-means_convergence.gif">K-Means gif</a> (wiki),<br>
      <a href="http://learningds.org/ch/24/clustering_intro.html">DS 100: Chapter 24</a> (clustering),
      <br>
      <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html">Python DS Handbook: Section 5.11</a> (K-Means),<br> 


      <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.12-gaussian-mixtures.html">Python DS Handbook: Section 5.12</a> (Gaussian Mixture Models),<br>
      <a href="https://en.wikipedia.org/wiki/Cluster_analysis">Cluster Analysis</a> (wiki) 

           
    </td>
	</tr>

  <tr>
    <td>Friday,<br> 10 November</td>
    <td></td>
    <td>
      <a href="work.html#slides">Project Draft / Interim Check-In</a>
    </td>
    <td></td>
  </tr>
	<tr>
    <td rowspan=2>Week 12:</td>
		<td rowspan="1">Wednesday,<br>15 November
		</td>
    
		<td> 
      Supervised vs. Unsupervised Learning;
      Replicability, P-Hacking, A/B testing<br><br>
      Regular Expressions</td>
    <td>
        <a href="work.html#cw12">Classwork 12</a>
    </td>
		<td> 
      <a href="https://www.ibm.com/cloud/blog/supervised-vs-unsupervised-learning">Supervised vs. Unsupervised Learning</a> (IBM)<br>
      <a href="http://learningds.org/ch/13/text_regex.html">DS 100: Sections 13.2-3</a> (Regular Expressions)
      <a href="http://learningds.org/ch/21/repl_intro.html">DS Chapter 21</a> (Replicability)<br>
      <a href="http://learningds.org/ch/13/text_regex.html">DS 100: Sections 13.2-3</a> (Regular Expressions)
    </td> 
	</tr>

  <tr>
    <td>Friday,<br> 17 November</td>
    <td></td>
    <td>
      <a href="work.html#p5">Program 5</a><br>      
    </td>
    <td></td>
  </tr>


  <tr>
    <td>22-24 November</td>
    <td colspan = 4><span style="color:darkblue">Thanksgiving Break:  No Classes</span></td>
  </tr>


	<tr>
    <td rowspan="2">Week 13:</td>
		<td rowspan="1">Wednesday,<br>29 November
		</td>
		<td>
      Relational Databases and SQL<br><br>
      Code Demo: SQL in Python: setting up a database, basic SQL, Subsetting, Aggregating, Joining, & Transforming Data
    </td>
		<td>
      <a href="work.html#cw13">Classwork 13</a>      
    </td>
    <td>
      <a href="http://learningds.org/ch/07/sql_intro.html">DS 100: Chapter 7</a> (Relational Databases & SQL)
		</td>
	</tr>

  <tr>
    <td>Friday,<br> 1 December</td>
    <td></td>
    <td>     
      <a href="work.html#completeSite">Project: Final Code, Slides Submission</a><br>
      <a href="work.html#presentation">Project: Pre-recorded Video Recording Submission (if not doing in-class live demo)</a>
    </td>
    <td></td>
  </tr>

	<tr>
    <td rowspan="2">Week 14:</td>
		<td rowspan="1">Wednesday,<br>6 December
		</td>
    <td colspan = 1> 
      More on SQL<br><br>
      Project Showcase<br><br>
      Semester Review 
    </td>
		<td>
      <a href="work.html#cw14">Classwork 14</a> 
    </td>
    <td>      <a href="http://learningds.org/ch/07/sql_intro.html">DS 100: Chapter 7</a> (Relational Databases & SQL)</td>
	</tr>

  <tr>
    <td>Friday,<br> 8 December</td>
    <td></td>
    <td>
      <a href="work.html#p6">Program 6</a> 
    </td>
    <td></td>
  </tr>

	<tr>
    <td></td>
		<td colspan=1>Wednesday, 12 December</td>
    <td colspan = 3>Reading Day-- no class</td>

	</tr>

	<tr>
    <td></td>
		<td colspan=1><b>Wednesday, 20 December<br>11:30am-1:30pm</b></td>
    <td colspan = 3><a href="work.html#final">Final Exam</a></td>
	</tr>
</table>


</div>



<div>
<i style="float:right">(This file was last modified on 20 October 2023.)</i><br>
</div>
