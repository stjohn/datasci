<!DOCTYPE doctype PUBLIC "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
  <meta http-equiv="Content-Type"
 content="text/html; charset=iso-8859-1">
  <title>Program 9, CSci 39542: Data Science, Hunter College</title>
</head>
<STYLE>A {text-decoration: none;}
th, td { padding: 5px; }
code {
  background-color: #eeeeee;
}
.inline {
  padding: 1px;
}
.blockcode {
  border: 1px solid #999999;
  display: block;
  padding-left: 10px;
  padding-top : 2px;
  padding-bottom : 2px;
  margin: 5px;
}
.datablock {
  border: 1px solid #eeeeee;
  display: block;
  padding: 7px;
  padding-top : 0px;
  margin: 5px;
}
</STYLE>
<body>


<div style="margin: 15px;width:100%;">
    <span style= "float: left;font-size:larger"><a href="index.html">CSci 39542</a></span>
    <span style= "float: right">
      <a href="syl.html">Syllabus</a>&nbsp;&nbsp;&nbsp;
      <a href="resources.html">Resources</a>&nbsp;&nbsp;&nbsp;
      <a href="work.html">Coursework</a><!--&nbsp;&nbsp;&nbsp;
      <a href="faq.html">FAQ</a>-->
    </span>
</div>

<br>
<br>
<hr>

<div style="margin:50px">


<h2>Program 9:  Logistic Taxi
  <br>CSci 39542: Introduction to Data Science<br>
<a href="http://www.hunter.cuny.edu/csci">Department of Computer Science</a><br>
<a href="https://hunter.cuny.edu">Hunter College</a>, <a href="https://www.cuny.edu">City University of New York</a><br>
Spring 2022<br><br>
</h2>


<hr>
<a href="work.html#cw">Classwork</a>&nbsp;&nbsp;&nbsp;
<a href="work.html#quizzes">Quizzes</a>&nbsp;&nbsp;&nbsp;
<a href="work.html#hw">Homework</a>&nbsp;&nbsp;&nbsp;
<a href="work.html#project">Project</a>&nbsp;&nbsp;&nbsp;
<hr>


<object width=100% height=50% type="text/html" data="generalNotes.html" border="0"
   style="overflow: hidden;">
</object>

<hr>

<h2>Program Description</h2>

<br>
   <p><a name="p9"><b>Program 9: Logistic Taxis.</b></b> &emsp; <i>Due noon, Thursday, 7 April.
     <br>Learning Objective:  to train and validate models, given quantitative and qualitative data, as well as assessing model quality.
     <br>Available Libraries: pandas, datetime, pickle, sklearn, and core Python 3.6+.
     (Note if you use our annonations, you should from typing import Union.)
     <br>Data Sources: <a href="https://data.cityofnewyork.us/Transportation/2020-For-Hire-Vehicles-Trip-Data/m3yx-mvk4">Yellow Taxi Trip Data</a> and <a href="https://data.cityofnewyork.us/Transportation/NYC-Taxi-Zones/d3c5-ddgc">NYC Taxi Zones</a> from OpenData NYC.
     <br>Sample Datasets:  <a href="../fall21/taxi_new_years_day_2020.csv">taxi_new_years_day_2020.csv</a>,
      <a href="../spr22/taxi_4July2020.csv">taxi_4July2020.csv</a>,
      <a href="taxi_jfk_june2020.csv">taxi_jfk_june2020.csv</a>, and
      <a href="taxi_zones.csv">taxi_zones.csv</a>.<br></i>

<br>
<p>
<a href="https://www1.nyc.gov/site/tlc/businesses/yellow-cab.page"><img src = "https://www1.nyc.gov/assets/tlc/images/content/pages/businesses/yellow-cab.png" height=300 alt="image of yellow taxi"></a>

<p>
As in  <a href="p8.html">Program 8</a>, this program is tailored to the NYC OpenData Yellow Taxi Trip Data and follows standard strategy for data cleaning and model building:
    <ol>
       <li> Read in datasets, merging and cleaning as needed.
       <li> Impute missing values (we will use median for the ordinal values and "most popular" for nominal values).
       <li> Use categorical encoding for qualitative values.
       <li> Split our dataset into training and testing sets.
       <li> Fit a model, or multiple models, to the training dataset.
       <li> Validate the models using the testing dataset.
    </ol>
To identify which trips are most likely to cross between boroughs, this program will focus on building a logistic regression model on both the categorical and numerical features of our dataset.
The function specifications are below:

<p>In your program, include the following functions from <a href="p8.html">Program 8</a>.  You may use your earlier functions or the Program 8 solution available on Blackboard:
<ul>
    <li> <code class = "inline">import_data(file_name) -> pd.DataFrame:</code>
      This function takes as one input parameter:
      <ul>
        <li> <code class = "inline">file_name</code>: the name of a CSV file containing <a href="https://data.cityofnewyork.us/Transportation/2020-For-Hire-Vehicles-Trip-Data/m3yx-mvk4">Yellow Taxi Trip Data</a> from OpenData NYC.
      </ul>
      The data in the file is read into a DataFrame, and the resulting DataFrame is returned.  <br>(Note this is identical to the function with the same name in <a href="p8.html">Program 8</a>.  You may use your earlier function or the Program 8 solution available on Blackboard.)
      <br>
    <li> <code class = "inline">add_tip_time_features(df) -> pd.DataFrame:</code>
      This function takes one input:
      <ul>
        <li> <code class = "inline">df</code>: a DataFrame containing <a href="https://data.cityofnewyork.us/Transportation/2020-For-Hire-Vehicles-Trip-Data/m3yx-mvk4">Yellow Taxi Trip Data</a> from OpenData NYC.
      </ul>
      The function computes 3 new columns:
      <ul>
        <li><code class = "inline">percent_tip</code>: which is <code class="inline">100*tip_amount/(total_amount-tip_amount)</code>
        <li><code class = "inline">duration</code>: the time the trip took in seconds.
        <li><code class = "inline">dayofweek</code>: the day of the week that the trip started, represented as 0 for Monday, 1 for Tuesday, ... 6 for Sunday.
      </ul>
      The original DataFrame with these additional three columns is returned.
      <br> (Note this is identical to the function with the same name in <a href="p8.html">Program 8</a>.  You may use your earlier function or the Program 8 solution available on Blackboard.)
      <br>
      <li> <code class = "inline">impute_numeric_cols(df, x_num_cols) -> pd.DataFrame:</code>
        This function takes two inputs:
        <ul>
          <li> <code class = "inline">df</code>: a DataFrame containing Yellow Taxi Trip Data from OpenData NYC.
          <li> <code class = "inline">x_num_cols</code>: a list of numerical columns in <code class = "inline">df</code>.
        </ul>
        Missing data in the columns <code class = "inline">x_num_cols</code> are replaced with the median of the column.  Returns a DataFrame containing only the imputed numerical columns from input <code class = "inline">df</code>.
    <br>(Note this is identical to the function with the same name in <a href="p8.html">Program 8</a>.  You may use your earlier function or the Program 8 solution available on Blackboard.)
  </ul>

And write the following new functions:

  <ul>
    <li> <code class = "inline">add_boro(df, file_name) -> pd.DataFrame:</code>
      This function takes as two input parameters:
      <ul>
          <li> <code class = "inline">df</code>: a DataFrame containing <a href="https://data.cityofnewyork.us/Transportation/2020-For-Hire-Vehicles-Trip-Data/m3yx-mvk4">Yellow Taxi Trip Data</a> from OpenData NYC.
          <li> <code class = "inline">file_name</code>: the name of a CSV file containing <a href="https://data.cityofnewyork.us/Transportation/NYC-Taxi-Zones/d3c5-ddgc">NYC Taxi Zones</a> from OpenData NYC.
      </ul>
      Makes a DataFrame, using <code class = "inline">file_name</code>, to add pick up and drop off boroughs to <code class = "inline">df</code>.
      In particular, adds two new columns to the <code class = "inline">df</code>:
      <ul>
        <li> <code class = "inline">PU_borough</code> that contain the borough corresponding to the pick up taxi zone ID (stored in <code class = "inline">PULocationID</code>), and
        <li> <code class = "inline">DO_borough</code> that contain the borough corresponding to the drop off taxi zone (stored in <code class = "inline">DOLocationID</code>)
      </ul>
      Returns <code class = "inline">df</code> with these two additional columns (<code class = "inline">PU_borough</code> and <code class = "inline">DO_borough</code>).

    <li> <code class = "inline">add_flags(df) -> pd.DataFrame:</code>
      This function takes one input parameter:
      <ul>
          <li> <code class = "inline">df</code>: a DataFrame containing <a href="https://data.cityofnewyork.us/Transportation/2020-For-Hire-Vehicles-Trip-Data/m3yx-mvk4">Yellow Taxi Trip Data</a> from OpenData NYC to which <code class = "inline">add_boro()</code> has been applied.
      </ul>
      Adds two new columns:
      <ul>
        <li> <code class = "inline">paid_toll</code> which is 1 if a toll was paid on the trip and 0 in no tolls were paid.
        <li> <code class = "inline">cross_boro</code> which is 1 if the trip started and ended in different borough, and 0 if the trip started and ended in the same borough.
      </ul>
      Returns <code class = "inline">df</code> with these two additional columns (<code class = "inline">paid_toll</code> and <code class = "inline">cross_boro</code>).
      <br>

    <li> <code class = "inline">encode_categorical_col(col,prefix) -> pd.DataFrame:</code>
      This function takes two input parameters:
      <ul>
          <li> <code class = "inline">col</code>: a column of categorical data.
          <li> <code class = "inline">prefix</code>: a prefix to use for the labels of the resulting columns.
      </ul>
      Takes a column of categorical data and uses categorical encoding to create a new DataFrame with the k-1 columns, where k is the number of different nomial values for the column.  Your function should create k columns, one for each value, labels by the prefix concatenated with the value.  The columns should be sorted and the DataFrame restricted to the first k-1 columns returned.  For example, if the column contains values:  'Bronx', 'Brooklyn', 'Manhattan', 'Queens', and 'Staten Island', and the  <code class = "inline">prefix</code> parameter has the value 'PU_' (and set the separators to be the empty string: <code class = "inline">prefix_sep=''</code>), then the resulting columns would be labeled: 'PU_Bronx', 'PU_Brooklyn', 'PU_Manhattan', 'PU_Queens', and 'PU_Staten Island'.  The last one alphabetically is dropped (in this example, 'PU_Staten Island') and the DataFrame restricted to the first k-1 columns is returned.  Note:  we presented several different ways to categorically encode nomial data in Lecture 14.  The book details an approach using sklearn in <a href="http://www.textbook.ds100.org/ch/20/feature_one_hot.html">Chapter 20</a>,
      and you may find <a href="https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html#pandas.get_dummies">Panda's get_dummies</a> useful.
      <br>

    <li> <code class = "inline">split_test_train(df, xes_col_names, y_col_name,
                       test_size=0.25, random_state=12345) -> Union[pd.DataFrame, pd.DataFrame, pd.Series(), pd.Series()]:</code>
      This function takes 5 input parameters:
       <ul>
           <li> <code class = "inline">df</code>: a DataFrame containing <a href="https://data.cityofnewyork.us/Transportation/2020-For-Hire-Vehicles-Trip-Data/m3yx-mvk4">Yellow Taxi Trip Data</a> from OpenData NYC to which <code class = "inline">add_boro()</code> has been applied.
           <li>  <code class = "inline">y_col_name</code>: the name of the column of the dependent variable.
           <li>  <code class = "inline">xes_col_names</code>: a list of columns that contain the independent variables.
           <li>  <code class = "inline">test_size</code>: accepts a float between 0 and 1 and represents the proportion of the data set to use for training.  This parameter has a default value of 0.25.
           <li>  <code class = "inline">random_state</code>:  Used as a seed to the randomization.  This parameter has a default value of 12345.
      </ul>
      Calls <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">sklearn's train_test_split</a> function to split the data set into a training and testing subsets:  x_train, x_test, y_train, y_test.  The resulting 4 subsets are returned.<br>
      Hint:  see the examples for <a href="p8.html">Program 8</a> for a similar splitting of data into training and testing datasets.

    <li> <code class = "inline">fit_logistic_regression(x_train, y_train,penalty='none',max_iter=1000) -> object:</code>

      This function takes four input parameter:
      <ul>
          <li> <code class = "inline">x_train</code>: the indepenent variable(s) for the analysis.
          <li> <code class = "inline">y_train</code>: the dependent variable for the analysis.
          <li> <code class = "inline">penalty</code>: the type of regularization applied.  The default value for this parameter is 'none'.
          <li> <code class = "inline">max_iter</code>: number of iterations allowed when fitting model.  The default value for this parameter is 1000.
      </ul>
      Fits a logistic regression model to the <code class = "inline">x_train</code> and
      <code class = "inline">y_train</code> data, using the logistic model from <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">sklearn.linear_model</a>.  The model should use the <code class = "inline">solver = 'saga'</code> to allow all the options for regularization (called <code class = "inline">penalty</code> as the option to the model) be any of <code class = "inline">'elasticnet'</code>, <code class = "inline">'l1'</code>,
      <code class = "inline">'l2'</code>, and <code class = "inline">'none'</code>).
      The parameter <code class = "inline">max_iter</code> should also be used when fitting the model.
      The resulting model should be returned as bytestream, using <a href="https://docs.python.org/3/library/pickle.html">pickle</a>.


    <li> <code class = "inline">predict_using_trained_model(mod_pkl, x, y) -> Union[float, float]: </code>

      This function takes three inputs:
      <ul>
        <li> <code class = "inline">mod_pkl</code>: a trained model for the data, stored in pickle format.
        <li> <code class = "inline">x</code>: an array or  DataFrame of numeric columns with no null values.
        <li> <code class = "inline">y</code>: an array or DataFrame of numeric columns with no null values.
      </ul>
      Computes and returns the mean squared error and r2 score between the values predicted by the model (<code class = "inline">mod</code> on <code class = "inline">x</code>) and the actual values (<code class = "inline">y</code>).  Note that <code class = "inline">sklearn.metrics</code> contains two functions that may be of use:  <code class = "inline">mean_squared_error</code> and <code class = "inline">r2_score</code>.

</ul>


<br><br>
<p>For example, let's start by setting up a DataFrame, as we did in <a href="p8.html">Program 8</a>, with the file, <a href="taxi_4July2020.csv">taxi_4July2020.csv</a>, add in the tip and time features, and imputing missing values for <code class = "inline">passenger_count</code>:

<pre><code class="blockcode">df = import_data('taxi_4July2020.csv')
df = add_tip_time_features(df)
df['passenger_count'] = impute_numeric_cols(df,['passenger_count'])
</code></pre>

Next, let's use our new functions to add in boroughs for the pick up and drop off locations:
<pre><code class="blockcode">df = add_boro(df,'taxi_zones.csv')
print('\nThe locations and borough columns:')
print(f"{df[['PULocationID','PU_borough','DOLocationID','DO_borough']]}")</code></pre>

<p>which prints out the new columns:
<pre><code class="datablock">The locations and borough columns:
        PULocationID PU_borough  DOLocationID DO_borough
0                 68  Manhattan           170  Manhattan
1                 48  Manhattan           239  Manhattan
2                142  Manhattan           264        NaN
3                 48  Manhattan            68  Manhattan
4                186  Manhattan            79  Manhattan
...              ...        ...           ...        ...
168930           138     Queens           231  Manhattan
168931            90  Manhattan           244  Manhattan
168932           229  Manhattan           140  Manhattan
168933           138     Queens           143  Manhattan
168934           132     Queens            25   Brooklyn

[168935 rows x 4 columns]
</code></pre>

<p>We can add the indicators for if a toll was paid and if the trip started and ended in different boroughs:
<pre><code class="blockcode">df = add_flags(df)
print(df[['trip_distance','PU_borough','DO_borough','paid_toll','cross_boro']])
</code></pre>
prints:
<pre><code class="datablock">       trip_distance PU_borough DO_borough  paid_toll  cross_boro
0                2.20  Manhattan  Manhattan          0           0
1                1.43  Manhattan  Manhattan          0           0
2                1.74  Manhattan        NaN          0           1
3                1.35  Manhattan  Manhattan          0           0
4                2.33  Manhattan  Manhattan          0           0
...               ...        ...        ...        ...         ...
168930           9.28     Queens  Manhattan          0           1
168931           9.10  Manhattan  Manhattan          0           0
168932           0.80  Manhattan  Manhattan          0           0
168933           9.55     Queens  Manhattan          1           1
168934          18.72     Queens   Brooklyn          0           1

[168935 rows x 5 columns]
</code></pre>

<p>
Let's explore the data some:
<pre><code class="blockcode">import matplotlib.pyplot as plt
import seaborn as sns
sns.set_theme(color_codes=True)

sns.lmplot(x="trip_distance", y="duration", data=df)
tot_r = df['trip_distance'].corr(df['duration'])
plt.title(f'All Taxi Trips from 4 July 2020 with r = {tot_r:.2f}')
plt.tight_layout()  #for nicer margins
plt.show()</code></pre>

<p>The resulting plot:
<p><img src="taxi_all_dist_v_duration.png" height = 300>

<p>There are some extremely long trips in there-- some over 100 miles.  To focus on trips that stay within the city, let's limit our data to trips that are less than 50 miles in distance, and explore the data by making scatter plots of some of the features:

<pre><code class="blockcode">df = df[df['trip_distance'] < 50]

sns.lmplot(x="trip_distance", y="duration", data=df)
tot_r = df['trip_distance'].corr(df['duration'])
plt.title(f'Taxi Trips from 4 July 2020 with r = {tot_r:.2f}')
plt.tight_layout()  #for nicer margins
plt.show()
sns.lmplot(x="trip_distance", y="paid_toll", data=df,fit_reg=False,y_jitter=0.1,
           scatter_kws={'alpha': 0.3})
dist_r = df['trip_distance'].corr(df['paid_toll'])
plt.title(f'Taxi Trips from 4 July 2020 with r = {dist_r:.2f}')
plt.tight_layout()  #for nicer margins
plt.show()
sns.lmplot(x="trip_distance", y="cross_boro", data=df,fit_reg=False,y_jitter=0.1,
           scatter_kws={'alpha': 0.3})
dist_r = df['trip_distance'].corr(df['cross_boro'])
plt.title(f'Taxi Trips from 4 July 2020 with r = {dist_r:.2f}')
plt.tight_layout()  #for nicer margins
plt.show()</code></pre>

<p>As discussed in Lecture 16 and <a href="http://www.textbook.ds100.org/ch/24/classification_cost.html">Chapter 24</a>, we added jitter to the y-values to better visualize the data since so much has similar values:

<p><img src="taxi_dist_v_duration.png" height = 300>
<img src="taxi_dist_v_paid_toll.png" height = 300>
<img src="taxi_dist_v_cross_boro.png" height = 300>


<p>
Interestingly, in our left image, the distance traveled and the duration of the trip are not strongly correlated.  The middle image show negative correlation between trip distance and paying tolls.  While the right images shows the trip distance positively correlated with trips that start and end in different boroughs.

<p>
Next, let's encode the categorical columns for pick up and drop off boroughs so we can use them as inputs for our model.

<pre><code class="blockcode">df_pu = encode_categorical_col(df['PU_borough'],'PU_')
print(df_pu.head())
df_do = encode_categorical_col(df['DO_borough'],'DO_')
print(df_do.head())</code></pre>

<p>The first few lines of the resulting DataFrames:

<pre><code class="datablock">   PU_Bronx  PU_Brooklyn  DO_EWR  PU_Manhattan  PU_Queens
0         0            0       0             1          0
1         0            0       0             1          0
2         0            0       0             1          0
3         0            0       0             1          0
4         0            0       0             1          0
   DO_Bronx  DO_Brooklyn  DO_EWR  DO_Manhattan  DO_Queens
0         0            0       0             1          0
1         0            0       0             1          0
2         0            0       0             0          0
3         0            0       0             1          0
4         0            0       0             1          0
</code></pre>

<p>Let's combine all the DataFrames into one (using <a href="https://pandas.pydata.org/docs/reference/api/pandas.concat.html">concat</a> along column axis):

<pre><code class="blockcode">df_all = pd.concat( [df,df_pu,df_do], axis=1)
print(f'The combined DataFrame has columns: {df_all.columns}')
</code></pre>

<p>The combined DataFrame has the columns:

<pre><code class="datablock">The combined DataFrame has columns:
Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',
       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',
       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',
       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',
       'total_amount', 'congestion_surcharge', 'percent_tip', 'duration',
       'dayofweek', 'DO_borough', 'PU_borough', 'paid_toll', 'cross_boro',
       'PU_Bronx', 'PU_Brooklyn', 'PU_EWR', 'PU_Manhattan', 'PU_Queens',
       'DO_Bronx', 'DO_Brooklyn', 'DO_EWR', 'DO_Manhattan', 'DO_Queens'],
      dtype='object')</code></pre>

For the taxi data, there is a special zone for trips to Newark Airport, and as such we have a drop off borough location of 'DO_EWR'.
We'll focus on the numeric columns, split our data into training and testing data sets:

<pre><code class="blockcode">x_col_names = ['passenger_count', 'trip_distance', 'RatecodeID', 'PULocationID',
          'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax',
          'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount',
          'congestion_surcharge', 'percent_tip', 'duration', 'dayofweek',
          'paid_toll', 'PU_Bronx', 'PU_Brooklyn', 'PU_Manhattan', 'PU_Queens',
          'DO_Bronx', 'DO_Brooklyn', 'DO_EWR', 'DO_Manhattan', 'DO_Queens']
y_col_name = 'cross_boro'
x_train, x_test, y_train, y_test = split_test_train(df_all, x_col_names, y_col_name)
</code></pre>


<p>Now, we're ready to fit some models to our data.  We'll try first just a single independent variable, <code class = "inline">trip_distance</code>, and build a logistic model without regularization, to predict when trips start in one borough and end in another (when <code class = "inline">cross_boro</code> is 1):


<pre><code class="blockcode">for p in ['none','l1','l2']:
print(f'Fitting a model with regression = {p}:')
    mod = fit_logistic_regression(x_train[['trip_distance']],y_train,penalty=p)
    mse_tr, r2_tr = predict_using_trained_model(mod,x_train[['trip_distance']],y_train)
    print(f'\ttraining data: mean squared error = {mse_tr:8.8} and r2 = {r2_tr:4.4}.')
    mse_val, r2_val = predict_using_trained_model(mod,x_test[['trip_distance']],y_test)
    print(f'\ttesting data: mean squared error = {mse_val:8.8} and r2 = {r2_val:4.4}.')</code></pre>

<p>Our training set of 75% of the data, does well both on both training and testing.  For this data, regularization does not significantly affect the results:

<pre><code class="datablock">Fitting a model with regression = none:
        training data: mean squared error = 0.08759994 and r2 = 0.3548.
        testing data: mean squared error = 0.087015201 and r2 = 0.3617.
Fitting a model with regression = l1:
        training data: mean squared error = 0.087663081 and r2 = 0.3543.
        testing data: mean squared error = 0.087038879 and r2 = 0.3616.
Fitting a model with regression = l2:
        training data: mean squared error = 0.08759994 and r2 = 0.3548.
        testing data: mean squared error = 0.087015201 and r2 = 0.3617.</code></pre>


<p>Let's use more of the numeric columns for a model, as well as different regularization approaches, and evaluate the results.  We increased the number of iterations to allow the model to converge.

<pre><code class="blockcode">x_cols = ['trip_distance','dayofweek','paid_toll', 'PU_Bronx', 'PU_Brooklyn','PU_Manhattan', 'PU_Queens']
print(f'For independent variables:  {x_cols}:')
for p in ['none','l1','l2']:
    print(f'Fitting a model with regression = {p}:')
    mod = fit_logistic_regression(x_train[x_cols],y_train,penalty=p,max_iter=2000)
    mse_tr, r2_tr = predict_using_trained_model(mod,x_train[x_cols],y_train)
    print(f'\ttraining data: mean squared error = {mse_tr:8.8} and r2 = {r2_tr:4.4}.')
    mse_val, r2_val = predict_using_trained_model(mod,x_test[x_cols],y_test)
    print(f'\ttesting data: mean squared error = {mse_val:8.8} and r2 = {r2_val:4.4}.')
</code></pre>

<p>All of the models do better with the training subset than the testing subset.  Adding regularization did not help the mean squared error, but showed some improvement for the r2 measure:

<pre><code class="datablock">For independent variables:
    ['trip_distance', 'dayofweek', 'paid_toll', 'PU_Bronx', 'PU_Brooklyn', 'PU_Manhattan', 'PU_Queens']:
Fitting a model with regression = none:
        training data: mean squared error = 0.072974957 and r2 = 0.4625.
        testing data: mean squared error = 0.072003599 and r2 = 0.4719.
Fitting a model with regression = l1:
        training data: mean squared error = 0.072974957 and r2 = 0.4625.
        testing data: mean squared error = 0.072003599 and r2 = 0.4719.
Fitting a model with regression = l2:
        training data: mean squared error = 0.072959172 and r2 = 0.4626.
        testing data: mean squared error = 0.071956244 and r2 = 0.4722.</code></pre>

</div>
</body>
</html>
